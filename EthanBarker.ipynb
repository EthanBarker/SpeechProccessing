{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB4U5jiSxNq_"
      },
      "source": [
        "# COM3502-4502-6502 Speech Processing - Python Programming Assignment\n",
        "\n",
        "## 1. General Information\n",
        "\n",
        "This programming assignment is worth 55% of the overall course mark.\n",
        "\n",
        "You are free to complete this assignment in your own time. However, feedback, advice and guidance is available during the lab classes and via the discussion board on Blackboard. \n",
        "\n",
        "Note: Via these channels we try to help you as much as possible, but will not debug your code or provide solutions to the assignment itself.\n",
        "\n",
        "Note: It will take some time to complete this assignment, so plan your work accordingly over the coming weeks. Read these instructions carefully.\n",
        "\n",
        "Note: Please be aware that students registered on COM4502 and COM6502 have **additional tasks** to perform. These are marked ‘COM4502-6502 Only’.\n",
        "\n",
        "Note: You should always ensure that your results (e.g. in terms of plots you create) are clear to undrestand and leave no room for mis-interpretation. This can often easily achieved by adding proper $x$- and $y$-axis labels, titles, legends etc. Where results are not clear to interprete, this might result in missed points. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kEIa0HOxNrC"
      },
      "source": [
        "## 1.1 Student Data\n",
        "\n",
        "Student Family Name: <span style=\"font-weight:bold;color:orange\">**Barker**</span>\n",
        "\n",
        "Student Given Name(s): <span style=\"font-weight:bold;color:orange\">**Ethan**</span>\n",
        "\n",
        "Date of submission: <span style=\"font-weight:bold;color:orange\">07/12/2022</span>\n",
        "\n",
        "Academic Year 2021/2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZnp8Pv7xNrD"
      },
      "source": [
        "## 1.2 Copyright\n",
        "\n",
        "This programming assignment is part of the lecture COM[3502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level3/com3502.html \"Open web page for COM3502 module\")-[4502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level4/com4502.html \"Open web page for COM4502 module\")-[6502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/msc/com6502.html \"Open web page for COM4502 module\") Speech Processing at the [University of Sheffield](https://www.sheffield.ac.uk/ \"Open web page of The University of Sheffield\"), Dept. of [Computer Science](https://www.sheffield.ac.uk/dcs \"Open web page of Department of Computer Science\"), University of Sheffield.\n",
        "\n",
        "This notebook is licensed as an assignment to be used during the lecture COM3502-4502-6502 Speech Processing at the University of Sheffield. Any further use is only permitted if agreed with the [module lead](mailto:s.goetze@sheffield.ac.uk).\n",
        "\n",
        "It should be a matter of course that rules of [unfair means](https://www.sheffield.ac.uk/apse/apo/quality/assessment/unfair) apply and the assignment is not to be shared with or made available to other persons besides those participating in the module during the same academic year. This includes publishing on web pages etc. All questions can be asked during the lab classes or using the Blackboard Discussion board.\n",
        "\n",
        "\n",
        "## 1.3 Hand-In Procedure and Deadline\n",
        "\n",
        "Once you have completed the assignment you should submit a `.zip` file (via Blackboard) containing your solution (as a file named `YourName.ipynb`) and possibly other source linked in your Jupyter Notebook. Also the `.zip` filename should be of the form `YourName.zip`. Please make also sure that your name is entered correctly in the section above.\n",
        "\n",
        "Standard departmental penalties apply for [late hand-in](https://sites.google.com/sheffield.ac.uk/comughandbook/general-information/assessment/late-submission) and [plagiarism](https://sites.google.com/sheffield.ac.uk/comughandbook/general-information/assessment/unfair-means).\n",
        "\n",
        "The **deadline** for handing-in this assignment (via Blackboard) is \n",
        "<span style=\"font-weight:bold;color:red\">**Friday 16th December 2022**</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uImKkZrxNrD"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task 0:**\n",
        "    \n",
        "Ensure that you data is correctly entered in the section at the top of this sheet and that the filename is in the form `YourName.ipynb`. \n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8rIeFZJxNrE"
      },
      "source": [
        "## 1.4 Libraries\n",
        "\n",
        "You should be familar to the use of the following Python libraries from the lab. You should not need to use additional ones. You are allowed to use additional libraries if necessary for your code. If they need to be installed by `!pip install <libraryname>` or `!conda install <libraryname>`, please indicate this as a comment in your code. You should not make use of libraries that can't be installed by either `!pip install` or `!conda install`. You have to ensure that your Notebook runs \"out of the box\". You can test this on the Computer Lab machines in the Diamond if you are unsure and using your own computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "hqBQHt2jxNrE"
      },
      "outputs": [],
      "source": [
        "#Let's do some necessary and nice-to-have imports\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt    # plotting\n",
        "#import seaborn as sns; sns.set()  # styling\n",
        "import numpy as np                 # math\n",
        "import soundfile as sf             # to load files\n",
        "from IPython import display as ipd # for sound playback\n",
        "from scipy import signal as sig           # filter designs (if not already imported)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7A-WYNzxNrF"
      },
      "source": [
        "## 2. Download, load, and analyse audio\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T1:** \n",
        "    \n",
        "* Load a wave file containing speech. You can find a file at <a href=\"https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/speech.wav\"> https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/speech.wav</a> and should be able to download this. You can also use your own WAVE files if you prefer this. If you want to record WAVE files and are using your own computer, the program [Audacity](https://www.audacityteam.org/download/) is one possibility to [record WAVE files](https://manual.audacityteam.org/man/basic_recording_editing_and_exporting.html).\n",
        "    \n",
        "* Visualise the signal in time domain, in the spectral domain (as spectrum) and as a time-frequency representation (spectrogram). Please ensure proper axis labels for all your plot in this assignment.\n",
        "\n",
        "* Playback the signal.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "shPud1AZFV5q"
      },
      "outputs": [],
      "source": [
        "#Import nextPowerOf2 from labs to help with task 1.\n",
        "def nextPowerOf2(L):\n",
        "    '''\n",
        "    Calculates the smallest power of 2 which is bigger than the length of input variable L\n",
        "    \n",
        "    This helper function can be used to calculate an appropriate \n",
        "    length for an DFT which is longer than the signal length L and is a power of 2.\n",
        "    \n",
        "    Input:\n",
        "        L: int\n",
        "            signal length\n",
        "    Output:\n",
        "        p: integer which is greater or equal than n and a power of 2\n",
        "    \n",
        "    Examples:\n",
        "        for L in range(20):\n",
        "            print('nextPowerOf2(L) for L='+str(L)+' is '+str(nextPowerOf2(L)))\n",
        "            \n",
        "        x=ones(11)\n",
        "        L_FFT=nextPowerOf2(len(x))\n",
        "    '''\n",
        "    return int(np.max([2,2**np.ceil(np.log2(L))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo-4N1zVxNrG"
      },
      "outputs": [],
      "source": [
        "#download\n",
        "file_name = 'speech.wav'\n",
        "!curl https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/{file_name} -o {file_name}\n",
        "\n",
        "#load \n",
        "s,fs = sf.read(file_name)\n",
        "length = 21\n",
        "\n",
        "# time vector in seconds\n",
        "t = np.linspace(0,len(s)/fs,len(s))\n",
        "\n",
        "#Find length of FFT and make spectrum\n",
        "FFT_length = nextPowerOf2(fs*length) # take a power of two which is larger than the signal length\n",
        "print(FFT_length) #prints length for own use\n",
        "spectrum = np.abs(np.fft.rfft(s,n=FFT_length))\n",
        "f = np.linspace(0, fs/2, num=int(FFT_length/2+1))\n",
        "\n",
        "#Plot the first graph for the time domain\n",
        "fig=plt.figure(figsize=(20,6))\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(t,s)\n",
        "plt.title('signal in time domain')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('x(t)')\n",
        "plt.grid()\n",
        "#Plot the second graph for frequency domain\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(f,spectrum)\n",
        "plt.title('signal in spectral domain')\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.ylabel('x(f)')\n",
        "plt.grid()\n",
        "#Plot the third graph for time - frequency domain\n",
        "plt.subplot(1,3,3)\n",
        "plt.specgram(s, Fs=fs);\n",
        "plt.title('signal as a time-frequency representation')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "\n",
        "#Play audio\n",
        "ipd.Audio(s, rate=fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeMoWngTxNrG"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
        "    \n",
        "**Question Q1:** \n",
        "\n",
        "* Determine the sampling frequency $f_s$ in Hz and the length of the signal in seconds. What is the sampling interval $T_s$ of your signal? What is the highest occuring frequency?\n",
        "    \n",
        "Note: You can either give your answer in form of a code block (e.g. by using the `print()` functions) or as text. For the latter, change the [type of the next cell](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#structure-of-a-notebook-document) from `code` to `markdown` or use the yellow example text below.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mahq7v0uxNrH"
      },
      "outputs": [],
      "source": [
        "print('The sampling frequency is ' + str(fs) + ' Hz and the length of the signal is ' + str(length) + \" seconds. The sampling interval is \" + str(1/fs) + \" seconds and the highest occuring freuqnecy is \" +str(fs/2)+ \" Hz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD_s8dgxxNrH"
      },
      "source": [
        "<span style=\"font-weight:bold;color:orange\">In case you want to answer by written text, we would appreciate if you  colour-code your answers, e.g. like using orange font colour as illustrated in this example. This helps us, not to overlook parts of your answers.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuQeGOs4xNrI"
      },
      "source": [
        "## 3. Piece-wise linear filtering in the time domain\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T2:** \n",
        "    \n",
        "* Design a high-pass filter with a cut-off frequency of $\\approx 500$ Hz using a filter design method of your choice. \n",
        "* Design a low-pass filter with a cut-off frequency of $\\approx 500$ Hz.\n",
        "* Design a band-stop filter with a cut-off frequencies of $\\approx 300$ Hz and of $\\approx 1.1$ kHz.\n",
        "* Simulate the effect of a land-line telephone by eliminating all energy below $300$ Hz and above $3,400$ Hz.\n",
        "* Visualise the transfer functions of the filters and the zero-pole plots.\n",
        "* Apply the designed filters, compare filter input and output as a time-frequency visualisation and play back the filtered signal.\n",
        "    \n",
        "Note: Don't forget proper labeling / description of your figures to make clear what is what.\n",
        "    \n",
        "Note: In case you encounter stability problems, rememer that we mentioned in the lecture, that filters can be designed as second-oder-systems (SOS) which the design methods you are familia with can realise.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "fs0iztBsSPFH"
      },
      "outputs": [],
      "source": [
        "#imported from previous lab for help with zeros and poles plotting\n",
        "def zplane(z, p, title='Poles and Zeros'):\n",
        "    \"Plots zeros and poles in the complex z-plane\"\n",
        "    ax = plt.gca()\n",
        "\n",
        "    ax.plot(np.real(z), np.imag(z), 'bo', fillstyle='none', ms=10)\n",
        "    ax.plot(np.real(p), np.imag(p), 'rx', fillstyle='none', ms=10)\n",
        "    unit_circle = plt.Circle((0, 0), radius=1, fill=False,\n",
        "                             color='black', ls='--', alpha=0.9)\n",
        "    ax.add_patch(unit_circle)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Re{$z$}')\n",
        "    plt.ylabel('Im{$z$}')\n",
        "    plt.axis('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgUajkMvkmxg"
      },
      "outputs": [],
      "source": [
        "def butter_highpass(cutoff, fs, order=5):\n",
        "  '''\n",
        "  butter highpass\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    cutoff : float\n",
        "       the cut off frequency in Hertz\n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz, default 44100\n",
        "    order : int\n",
        "        The order of the highpass\n",
        "  '''\n",
        "  return sig.butter(order, cutoff, fs = fs, btype= 'high', analog = False )\n",
        "  \n",
        "def butter_highpass_filter(data, cutoff, fs, order=10):\n",
        "  '''\n",
        "  butter highpass filter\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : float\n",
        "       the input data \n",
        "    cutoff : float\n",
        "       the cut off frequency in Hertz\n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz, default 44100\n",
        "    order : int\n",
        "        The order of the highpass\n",
        "\n",
        "  '''\n",
        "  b, a = sig.butter(10, cutoff, fs = fs, btype= 'high', analog = False)\n",
        "  y = sig.lfilter(b ,a, data)\n",
        "  return y  \n",
        "\n",
        "#Set cutoff to 500Hz\n",
        "cutoff = 500\n",
        "#Design a highpass with order 10 using butter method\n",
        "b, a = butter_highpass( cutoff, fs , 10)\n",
        "w, h = sig.freqz(b, a, fs = fs, worN = 8000)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Lowpass Filter at frequency of 500Hz')\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.plot(w, np.abs(h))\n",
        "plt.xlim(0,1000)\n",
        "plt.plot(cutoff, 0.5*np.sqrt(2), 'ko-')\n",
        "plt.grid()\n",
        "plt.axvline(cutoff, color='red')\n",
        "plt.subplot(1,2,2)\n",
        "z, p, k = sig.tf2zpk(b, a)\n",
        "zplane(np.roots(z), np.roots(p))\n",
        "plt.grid()\n",
        "plt.title(\"Zero-Pole Plot\")\n",
        "plt.xlabel('Real')\n",
        "plt.ylabel('Imaginary')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Play the audio\n",
        "high_pass_audio = butter_highpass_filter(s, cutoff, fs, order=10)\n",
        "ipd.Audio(high_pass_audio, rate = fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTAYFvBExNrI"
      },
      "outputs": [],
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "  '''\n",
        "  butter lowpass\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    \n",
        "    cutoff : float\n",
        "       the cut off frequency in Hertz\n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz\n",
        "    order : int\n",
        "        The order of the lowpass\n",
        "  \n",
        "  '''\n",
        "  return sig.butter(order, cutoff, fs = fs, btype= 'low', analog = False)\n",
        "  \n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=10):\n",
        "  '''\n",
        "    butter lowpass filter\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : float\n",
        "       the input data \n",
        "    cutoff : float\n",
        "       the cut off frequency in Hertz\n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz\n",
        "    order : int\n",
        "        The order of the lowpass\n",
        "\n",
        "  '''\n",
        "  b, a = sig.butter(10, cutoff, fs = fs, btype= 'low', analog = False)\n",
        "  y = sig.lfilter(b ,a, data)\n",
        "  return y\n",
        "#Set cutoff to 500Hz\n",
        "cutoff = 500\n",
        "#Design a lowpass with order 10 using butter method\n",
        "b, a = butter_lowpass( cutoff, fs , 10)\n",
        "w, h = sig.freqz(b, a, fs = fs, worN = 8000)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Lowpass Filter at frequency of 500Hz')\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.plot(w, np.abs(h))\n",
        "plt.xlim(0,1000)\n",
        "plt.plot(cutoff, 0.5*np.sqrt(2), 'ko-')\n",
        "plt.grid()\n",
        "plt.axvline(cutoff, color='red')\n",
        "plt.subplot(1,2,2)\n",
        "z, p, k = sig.tf2zpk(b, a)\n",
        "zplane(np.roots(z), np.roots(p))\n",
        "plt.grid()\n",
        "plt.title(\"Zero-Pole Plot\")\n",
        "plt.xlabel('Real')\n",
        "plt.ylabel('Imaginary')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Play the audio\n",
        "low_pass_audio = butter_lowpass_filter(s, cutoff, fs, order=10)\n",
        "ipd.Audio(low_pass_audio, rate = fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jFVRx1WlsvE"
      },
      "outputs": [],
      "source": [
        "def butter_bandstop(lowcut, highcut, fs, order=5):\n",
        "    '''\n",
        "    butter bandstop\n",
        "    lowcut : float\n",
        "       the lowcut frequency in Hz\n",
        "    highcut : float\n",
        "       the highcut frequency in Hz   \n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz\n",
        "    order : int\n",
        "        The order of the bandstop\n",
        "    '''\n",
        "    return sig.butter(order, [lowcut, highcut], fs=fs, btype='bandstop')\n",
        "    \n",
        "\n",
        "def butter_bandstop_filter(data, lowcut, highcut, fs, order=5):\n",
        "    '''\n",
        "    butter bandstop filter\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : float\n",
        "       the input data\n",
        "    lowcut : float\n",
        "       the lowcut frequency in Hz\n",
        "    highcut : float\n",
        "       the highcut frequency in Hz \n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz\n",
        "    order : int\n",
        "        The order of the bandstop filter\n",
        "\n",
        "    '''\n",
        "    b, a = butter_bandstop(lowcut, highcut, fs, order=order)\n",
        "    y = sig.lfilter(b, a, data)\n",
        "    return y\n",
        "#set range to exclude between 300-1100Hz\n",
        "lowcut = 300\n",
        "highcut = 1100\n",
        "#Design a bandstop with order 5 and the cuts provided\n",
        "b, a = butter_bandstop(lowcut, highcut, fs, order=5)\n",
        "w, h = sig.freqz(b, a, fs=fs, worN=8000)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(w, abs(h))\n",
        "plt.title('Bandstop filter with 300 as the low cut and 1100 as the high cut')\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.xlim(0,2200)\n",
        "plt.grid()\n",
        "plt.axvline(lowcut, color='red')\n",
        "plt.axvline(highcut, color='red')\n",
        "plt.subplot(1,2,2)\n",
        "z, p, k = sig.tf2zpk(b, a)\n",
        "zplane(np.roots(z), np.roots(p))\n",
        "plt.grid()\n",
        "plt.title(\"Zero-Pole Plot\")\n",
        "plt.xlabel('Real')\n",
        "plt.ylabel('Imaginary')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Play the audio\n",
        "bandstop_audio = butter_bandstop_filter(s, lowcut, highcut , fs, order=5)\n",
        "ipd.Audio(bandstop_audio, rate = fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XafWZvDqHBvR"
      },
      "outputs": [],
      "source": [
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    '''\n",
        "    butter bandpass\n",
        "    lowcut : float\n",
        "       the lowcut frequency in Hz\n",
        "    highcut : float\n",
        "       the highcut frequency in Hz   \n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz\n",
        "    order : int\n",
        "        The order of the bandpass\n",
        "    '''\n",
        "    return sig.butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    '''\n",
        "    butter bandpass filter\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : float\n",
        "       the input data\n",
        "    lowcut : float\n",
        "       the lowcut frequency in Hz\n",
        "    highcut : float\n",
        "       the highcut frequency in Hz \n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz\n",
        "    order : int\n",
        "        The order of the bandpass filter\n",
        "\n",
        "    '''\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = sig.lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "#Define the range of values accepted, 300-3400Hz\n",
        "lowcut = 300\n",
        "highcut = 3400\n",
        "#Define a bandpass filter of order 5\n",
        "b, a = butter_bandpass(lowcut, highcut, fs, order=5)\n",
        "w, h = sig.freqz(b, a, fs=fs, worN=8000)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(w, abs(h))\n",
        "plt.title('Bandpass filter with 300 as the low cut and 3400 as the high cut')\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.xlim(0,5000)\n",
        "plt.grid()\n",
        "plt.axvline(lowcut, color='red')\n",
        "plt.axvline(highcut, color='red')\n",
        "plt.subplot(1,2,2)\n",
        "z, p, k = sig.tf2zpk(b, a)\n",
        "zplane(np.roots(z), np.roots(p))\n",
        "plt.grid()\n",
        "plt.title(\"Zero-Pole Plot\")\n",
        "plt.xlabel('Real')\n",
        "plt.ylabel('Imaginary')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Play the audio\n",
        "bandpass_audio = butter_bandpass_filter(s, lowcut, highcut , fs, order=5)\n",
        "ipd.Audio(bandpass_audio, rate = fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoBHZ8l_xNrI"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
        "    \n",
        "**Question Q2:** \n",
        "\n",
        "* Explain the behaviour of the designed band-stop filter, i.e. describe (briefly) what you can see in the generated plots. If you didn't generate plots you can explain what you would expect to see.\n",
        "\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyBJ2C-8xNrI"
      },
      "source": [
        "**Answer to Question Q2:**\n",
        "\n",
        "<span style=\"font-weight:bold;color:orange\">\n",
        "    The band-stop filter blocks and rejects frequencies that lie between the two values set in the cut-off frequency points. In this plot you see there is no frequency between 300Hz and 1100Hz. \n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiTOaNWOxNrJ"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
        "    \n",
        "**Question Q3:**\n",
        "    \n",
        "* Which sounds are most affected when the low-pass cut-off frequency is set to around $500$\n",
        "Hz - vowels or consonants - and why?\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g-KKYiGxNrJ"
      },
      "source": [
        "**Answer to Question Q3:**\n",
        "\n",
        "<span style=\"font-weight:bold;color:orange\">\n",
        "    Specific consonants such as \"k, p, s, t\" all have a frequency range above 500 Hz. They are usually in the 2 kHz-4 kHz range. Hence, a low-pass filter would block these sounds as it would not allow anything over 500Hz.\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQOO2NoMxNrJ"
      },
      "source": [
        "## 4. Audio Effects\n",
        "\n",
        "### 4.1 Low Frequency Oscillator\n",
        "\n",
        "Many ‘Voice effects (FX)’ are achieved by modifying some characteristic of the speech using a low frequency oscillator or *LFO*. LFOs typically have two controls: speed (which is specified by the frequency in Hertz) and depth (which specifies the magnitude of the effect). The following tasks will require several LFOs, so it makes sense to implement one in the following.\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T3:**\n",
        "    \n",
        "* Implement a Low Frequency Oscillator as a function `lfo()` as described below. Visualise that your function works be generating a sine and a square wave of frequency $5$ Hz and length $2$ seconds with different depths.\n",
        "    \n",
        "Note: There will be an extra point in the marking if you **do not** use the `scipy` library to solve this task.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "0mR8bN8vxNrJ"
      },
      "outputs": [],
      "source": [
        "def lfo(speed_hz, depth, num_samples, fs=44100, square_curve=False):\n",
        "    '''\n",
        "    Low-frequency oscillator\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    speed_hz : float\n",
        "       frequency of generated signal in Hertz\n",
        "    depth : float\n",
        "        magnitude of the effect\n",
        "    num_samples : int\n",
        "        length of the signal in samples\n",
        "    fs : float, optional \n",
        "        sampling frequency in Hz, default 44100\n",
        "    square_curve : boolean, optional (default: False)\n",
        "        generate square wave if true, generate sine wave if false\n",
        "\n",
        "    Example use:\n",
        "    -------\n",
        "        sig_square = lfo(speed_hz=5, depth=0.7, num_samples=88200, fs=44100, square_curve=True)\n",
        "    '''\n",
        "    # Time specifications:\n",
        "    dt = 1/fs # seconds per sample\n",
        "    StopTime = num_samples / fs # length in seconds\n",
        "    t = np.arange(0,StopTime,dt) # time vector in seconds\n",
        "    #GenerateLFO\n",
        "    x = depth*np.sin(2*np.pi*speed_hz*t) \n",
        "    #Generate Square Curve\n",
        "    if square_curve == True:\n",
        "      x = np.where(x>0, depth, -depth)\n",
        "    return x    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiAc-FHxxNrJ"
      },
      "outputs": [],
      "source": [
        "#Create signals\n",
        "sig_sin = lfo(speed_hz=4, depth=0.7, num_samples=88200, fs=44100, square_curve=False)\n",
        "sig_sin2 = lfo(speed_hz=2, depth=0.4, num_samples=88200, fs=44100, square_curve=False)\n",
        "sig_square = lfo(speed_hz=6, depth=0.8, num_samples=88200, fs=44100, square_curve=True)\n",
        "sig_square2 = lfo(speed_hz=3, depth=0.3, num_samples=88200, fs=44100, square_curve=True)\n",
        "#Define variables needed to plot\n",
        "num_samples=88200\n",
        "dt = 1/fs\n",
        "StopTime = num_samples / fs\n",
        "t = np.arange(0,StopTime,dt)\n",
        "#Plot graphs\n",
        "fig=plt.figure(figsize=(40,8))\n",
        "plt.subplot(1,4,1)\n",
        "plt.title('sine wave of frequency 4 Hz and length 2 seconds with depth 0.7')\n",
        "plt.plot(t,sig_sin,\"red\")\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.grid()\n",
        "plt.subplot(1,4,2)\n",
        "plt.title('square wave of frequency 2 Hz and length 2 second with depth 0.4')\n",
        "plt.plot(t,sig_square,\"blue\")\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.grid()\n",
        "plt.subplot(1,4,3)\n",
        "plt.title('sine wave of frequency 6 Hz and length 2 seconds with depth 0.8')\n",
        "plt.plot(t,sig_sin2,\"green\")\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.grid()\n",
        "plt.subplot(1,4,4)\n",
        "plt.title('square wave of frequency 3 Hz and length 2 second with depth 0.3')\n",
        "plt.plot(t,sig_square2,\"orange\")\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNN2UZdxNrK"
      },
      "source": [
        "Although your function outputs audio, you are unlikely to be able to hear it as the frequency is so low. However, you can check that it is functioning correctly by combining is with other audio signals as we will do in the following.\n",
        "\n",
        "### 4.2 Amplitude Modulation - Tremolo\n",
        "\n",
        "*Tremolo* is one of the most basic voice manipulations that makes use of an LFO. In this effect, the amplitude of a speech signal is [modulated](https://en.wikipedia.org/wiki/Amplitude_modulation), i.e. the speech waveform is multiplied by a variable gain that ranges between $0$ and $1$. \n",
        "\n",
        "Your LFO outputs an audio signal between `-depth` and `+depth`. So, in order to modulate the amplitude of the speech correctly, the output of the LFO has to be scaled appropriately to range between $0$ and $1$.\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T4:**\n",
        "    \n",
        "* Implement  a function `tremolo()` using your function `lfo()` and modulate the amplitude of the speech signal. \n",
        "* Experiment with different settings for `speed` and `depth`. In particular, note that a square wave with speed between $3$ and $4$ Hz (and depth = $1$) has a very destructive effect on the intelligibility of the output. This is because $3-4$ Hz corresponds to the typical syllabic rate of speech.\n",
        "* Proof that the effect works by a proper visualisation of the filtered speech signal and describe what can be observed and perceived.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "AgSr0JfhxNrK"
      },
      "outputs": [],
      "source": [
        "def tremolo(signal, fs, speed_hz, depth, square_curve=False):\n",
        "    '''\n",
        "    Applies a tremolo effect to a signal\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : float\n",
        "       signal to which the effect is applied\n",
        "    fs : int\n",
        "        sampling frequency in Hz\n",
        "    speed_hz : float\n",
        "       frequency of LFO and by this also the effect\n",
        "    depth : float\n",
        "        magnitude of the effect\n",
        "    square_curve : boolean, optional\n",
        "        generate square wave if true, generate sine wave if false\n",
        "    \n",
        "    Return\n",
        "    ----------\n",
        "    signal after application of tremolo effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_tremolo = tremolo(audio_in, fs, 10, 1, square_curve=False)\n",
        "    '''\n",
        "    #Generate an LFO using lfo() function\n",
        "    generated_signal = lfo(speed_hz, depth, 928086, fs, square_curve)\n",
        "    # apply effect of tremolo\n",
        "    output_signal = signal * (1 + depth * generated_signal)\n",
        "    return output_signal\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFFTUtFLxNrK"
      },
      "outputs": [],
      "source": [
        "#Create a tremolo signal\n",
        "signal_tremolo = tremolo(s, fs, 3, 1, square_curve=True)\n",
        "t = np.arange(0,StopTime,dt)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.title('Input sound file')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.plot(s)\n",
        "plt.grid()\n",
        "plt.subplot(1,3,2)\n",
        "plt.title('Output sound file')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.plot(signal_tremolo)\n",
        "plt.grid()\n",
        "plt.subplot(1,3,3)\n",
        "plt.title('Input sound with the new output to show the difference')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.plot(signal_tremolo, \"blue\")\n",
        "plt.plot(s, \"red\")\n",
        "plt.grid()\n",
        "ipd.Audio(signal_tremolo, rate = fs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcsrHtzNxNrK"
      },
      "source": [
        "### 4.3 Ring Modulation\n",
        "\n",
        "Another basic effect is to multiply the speech signal by the output of an LFO. This is known as ‘ring modulation’.\n",
        "\n",
        "Note: In the BBC TV series [Dr. Who](https://en.wikipedia.org/wiki/Doctor_Who), the voices of the alien [Daleks](https://en.wikipedia.org/wiki/Dalek) are generated by a ring modulator with an LFO set to around 30 Hz. The voice actors also spoke using a stilted monotonic intonation in order to enhance the effect. You can try this yourself by recording your own voice and applying the effect.\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T5 (Ring Modulation):**\n",
        "    \n",
        "* Implement  a function `ring_modulation()` using your function `lfo()` and modulate the amplitude of the speech signal by multiplying with the LFO signal. \n",
        "* Experiment with different settings for `speed` and `depth`. Note how the timbre of the resulting sound is subtly different from *tremolo*.\n",
        "* Proof that the effect works by a proper visualisation of the filtered speech signal and describe what can be observed and perceived.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "y90r8W1dxNrL"
      },
      "outputs": [],
      "source": [
        "def ring_modulation(signal, fs, speed_hz, depth, square_curve=False):\n",
        "    '''\n",
        "    Applies a ring modulation effect to a signal\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : float\n",
        "       signal to which the effect is applied\n",
        "    fs : int\n",
        "        sampling frequency in Hz\n",
        "    speed_hz : float\n",
        "       frequency of LFO and by this also the effect\n",
        "    depth : float\n",
        "        magnitude of the effect\n",
        "    square_curve : boolean, optional\n",
        "        generate square wave if true, generate sine wave if false\n",
        "    \n",
        "    Return\n",
        "    ----------\n",
        "    signal after application of the ring modulation effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_ring_mod = ring_modulation(audio_in, fs, 10, 1, square_curve=False)\n",
        "    '''\n",
        "    #Generate an LFO using lfo() function\n",
        "    generated_signal = lfo(speed_hz, depth, 928086, fs, square_curve)\n",
        "    #Multiply generated signal by input\n",
        "    output_signal = generated_signal * signal\n",
        "    return output_signal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-G2qa9bxNrL"
      },
      "outputs": [],
      "source": [
        "#Create modulated signal\n",
        "signal_modulated = ring_modulation(s,fs,30,0.5,False)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.title('Input sound file')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.plot(s)\n",
        "plt.grid()\n",
        "plt.subplot(1,3,2)\n",
        "plt.title('Output sound file')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.plot(signal_modulated)\n",
        "plt.grid()\n",
        "plt.subplot(1,3,3)\n",
        "plt.title('Input sound with the new output to show the difference')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.plot(s, \"red\")\n",
        "plt.plot(signal_modulated, \"blue\")\n",
        "plt.grid()\n",
        "ipd.Audio(signal_modulated, rate = fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u968xfK6xNrL"
      },
      "source": [
        "### 4.4 Frequency Shifting\n",
        "\n",
        "Many Vocal FX are the result of altering the frequencies present, e.g. changing the pitch of a voice. There are many algorithms for frequency shifting. You have already implemented an approximate solution with your ring modulator.\n",
        "\n",
        "For simplicity, the following function will be givem implementing frequency shifting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "mPThQMnixNrL"
      },
      "outputs": [],
      "source": [
        "# the following code in this cell is taken and slightly adapted from:\n",
        "# https://gist.github.com/lebedov/4428122\n",
        "\n",
        "import scipy.signal as sig\n",
        "\n",
        "def nextpow2(n):\n",
        "    '''Return the first integer N such that 2**N >= abs(n)'''\n",
        "    return int(np.ceil(np.log2(np.abs(n))))\n",
        "\n",
        "def frequency_shift(signal, fs, shift_amount):\n",
        "    '''\n",
        "    Shift the specified signal by the specified frequency.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : float\n",
        "       input signal to which the effect should be applied\n",
        "    fs : int\n",
        "        sampling frequency in Hz\n",
        "    shift_amount : float\n",
        "       amount of frequency shift (in Hz)\n",
        "   \n",
        "    Return\n",
        "    ----------\n",
        "    signal after application of the frequancy shifting effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_frequency_shifted = frequency_shift(audio_in, fs, 100)\n",
        "    '''\n",
        "\n",
        "    # Pad the signal with zeros to prevent the FFT invoked by the transform from\n",
        "    # slowing down the computation:\n",
        "    N_orig = len(signal)\n",
        "    N_padded = 2 ** nextpow2(N_orig)\n",
        "    t = np.arange(0, N_padded)\n",
        "    return (\n",
        "        sig.hilbert(\n",
        "            np.hstack((signal, np.zeros(N_padded - N_orig, signal.dtype)))\n",
        "        )\n",
        "        * np.exp(2j * np.pi * shift_amount * t / fs)\n",
        "    )[:N_orig].real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtgOo-8jxNrL"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T6 (Frequency Shifting):**\n",
        "    \n",
        "* Visualise the effect of the frequency shift effect using an appropriate spectral representation.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt8AT4FkxNrM"
      },
      "outputs": [],
      "source": [
        "#Create two shifts one posetive and one negative\n",
        "signal_frequency_shifted = frequency_shift(s, fs, 2000)\n",
        "signal_frequency_shifted2 = frequency_shift(s, fs, -2000)\n",
        "#Plot the graphs\n",
        "fig=plt.figure(figsize=(30,8))\n",
        "plt.subplot(1,3,1)\n",
        "plt.title('Signal s as a spectogram')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.specgram(s, Fs=fs);\n",
        "plt.subplot(1,3,2)\n",
        "plt.title('Signal s shfted by 2000 Hz as a spectogram')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.specgram(signal_frequency_shifted, Fs=fs);\n",
        "plt.subplot(1,3,3)\n",
        "plt.title('Signal s shfted by -2000 Hz as a spectogram')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.specgram(signal_frequency_shifted2, Fs=fs);\n",
        "ipd.Audio(signal_frequency_shifted, rate = fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YumXFDkZxNrM"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
        "    \n",
        "**Question Q4:**\n",
        "\n",
        "* COM3502-4502-6502: Why can the voice be shifted up in frequency much further than\n",
        "it can be shifted down in frequency before it becomes severely distorted? Hint: Calculate a spectrum plot if the answer is not immediately clear to you.\n",
        "* COM4502-6502 ONLY: Your frequency shifter changes all the frequencies present in an input signal. How might it be possible to change the pitch of a voice without altering the formant frequencies?\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91KJz1XexNrM"
      },
      "source": [
        "**Answer to Question Q4:**\n",
        "\n",
        "<span style=\"font-weight:bold;color:orange\">\n",
        "    Human voice has a frequency ranging from 80Hz to 250Hz. The voice in the recording can only be shifted down by a max of 250Hz. On the other hand, humans can hear up to 20,000Hz so it can be shifted up much more than It can be shifted down as the difference is approximately 19,750Hz. \n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYaTpgCJxNrM"
      },
      "source": [
        "### 4.5 Harmony Effect\n",
        "\n",
        "A classic ‘robotic’ voice can be achieved by simply adding frequency-shifted speech back to the unprocessed original. This effect is known as ‘harmony’. However, rather than simply adding the signals in equal amounts, we will implement a more general purpose approach.\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T7:**\n",
        "    \n",
        "* Implement a function `mixer()` that adds the original speech with the manipulated speech in different proportions. \n",
        "* Implement a function `harmony()` mixes the input signal with a frequency shifted version of itself (using the funtions `mixer()` and `frequency_shift()`). With your mixer at the 50-50 setting, experiment with different frequency shifts in order to produce the best robotic sounding output. Report \"your optimal\" setting. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "Ibrsw1x_xNrM"
      },
      "outputs": [],
      "source": [
        "def mixer(signal1, signal2, percentage_l=0.5):\n",
        "  '''\n",
        "    Applies a mixer effect to a signal\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal1 : float\n",
        "       signal to which the effect is applied\n",
        "    signal2 : float\n",
        "       manipulated speech to which effects the origional signal\n",
        "    percentage_l : float\n",
        "       splits the signal into different proportions\n",
        "    \n",
        "    Return\n",
        "    ----------\n",
        "    signal after application of a mixer effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_mixed = mixer(signal1, signal2, 0.4)\n",
        "    '''\n",
        "    #Mixer function\n",
        "  output_signal = ((1-percentage_l)*signal1) + (percentage_l*signal2)\n",
        "  return output_signal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "3wyS-nTbxNrM"
      },
      "outputs": [],
      "source": [
        "def harmony(signal1, fs, shift_amount,percentage_l):\n",
        "  '''\n",
        "    Applies a harmony effect to a signal\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal1 : float\n",
        "       signal to which the effect is applied\n",
        "    fs : int\n",
        "        sampling frequency in Hz\n",
        "    shift_amount : float\n",
        "       amount of frequency shift (in Hz)\n",
        "    percentage_l : float\n",
        "       splits the signal into different proportions   \n",
        "    Return\n",
        "    ----------\n",
        "    signal after application of a harmony effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_harmony = harmony(audio_in, fs, 100, 0.5)\n",
        "    '''\n",
        "    #shift the frequency of a signal\n",
        "  signal_frequency_shifted = frequency_shift(signal1, fs, shift_amount)\n",
        "  #mix this shifted frequency signal\n",
        "  output_signal = mixer(signal_frequency_shifted,signal_frequency_shifted,percentage_l)\n",
        "  return output_signal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLEm-gvMxNrM"
      },
      "outputs": [],
      "source": [
        "#Call harmony function\n",
        "x = harmony(s,fs,100,0.5)\n",
        "#Play audio\n",
        "ipd.Audio(x, rate=fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVl9o9_WxNrN"
      },
      "source": [
        "**Answer to question in Task T7:**\n",
        "\n",
        "<span style=\"font-weight:bold;color:orange\">\n",
        "  My optimal setting is 100Hz because from trial and error this is the most robotic sound I can find\n",
        "\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hImERhQQxNrN"
      },
      "source": [
        "### 4.6 Frequency Modulation: Vibrato\n",
        "\n",
        "Now that you have the ability to shift the frequencies in a speech signal, it is very easy to implement another common voice manipulation technique - *vibrato*. All that is required is for the frequency shifter to be controlled by the output of an LFO.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T8:**\n",
        "    \n",
        "* Implement a function `vibrato()` by connecting an LFO to your frequency shifter, and experiment with different values for speed and depth . Note that the LFO output will need to be scaled to provide an appropriate frequency shift range and then added to the output of the frequency shift.\n",
        "    \n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "193K4A-dxNrN"
      },
      "outputs": [],
      "source": [
        "def vibrato(signal, shift_amount, speed_hz, depth, num_samples, fs, square_curve):\n",
        "  '''\n",
        "  Applies a vibrato effect to a signal\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : float\n",
        "       signal to which the effect is applied\n",
        "    shift_amount : float\n",
        "       amount of frequency shift (in Hz)\n",
        "    speed_hz : float\n",
        "       frequency of LFO and by this also the effect\n",
        "    depth : float\n",
        "        magnitude of the effect\n",
        "    num_samples : int\n",
        "        length of the signal in samples             \n",
        "    fs : int\n",
        "        sampling frequency in Hz\n",
        "    square_curve : boolean, optional\n",
        "        generate square wave if true, generate sine wave if false    \n",
        "    \n",
        "    Return\n",
        "    ----------\n",
        "    signal with avibrato effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_vibrato = vibrato(audio_in, 5, 30, 0.8, num_samples, fs, False)\n",
        "  '''\n",
        "  #Generate a signal\n",
        "  generated_signal = lfo(speed_hz, depth, num_samples , fs, square_curve)\n",
        "  #Apply a frequency shift of a set amount in Hz\n",
        "  output_signal = frequency_shift(generated_signal, fs, shift_amount)\n",
        "  return output_signal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBeasB72xNrN"
      },
      "outputs": [],
      "source": [
        "#Plot vibrato\n",
        "fig=plt.figure(figsize=(30,8))\n",
        "plt.title('Vibrato representation')\n",
        "plt.xlabel('Amplitude')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.plot(vibrato(s,5,5,0.7,num_samples,fs,False))\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jytNQr86xNrN"
      },
      "source": [
        "### 4.7 Time Delay Effect - Echo and Comb Filter\n",
        "\n",
        "Many interesting voice FX can be achieved by delaying the signal and recombining it with itself. \n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T9:**\n",
        "    \n",
        "* Implement a function `echo()` which mixes a signal $s(t)$ with itself in a delayed version, i.e. $s(t-t_0)$. Experiment with various values for the delay $t_0$, and note the different effects you can achieve with delays \n",
        "  * below $20$ msecs\n",
        "  * between $20$ and $100$ msecs, and \n",
        "  * above $100$ msecs.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "M1U-k9vNxNrN"
      },
      "outputs": [],
      "source": [
        "def echo(signal,delay,fs):\n",
        "  '''\n",
        "    Applies an echo effect to a signal\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : float\n",
        "       signal to which the effect should be applied\n",
        "    delay : float\n",
        "       how long you want the delay to be in seconds\n",
        "    fs : int\n",
        "        sampling frequency in Hz\n",
        "    \n",
        "    Return\n",
        "    ----------\n",
        "    signal with an echo effect\n",
        "    \n",
        "    Example use:\n",
        "    -------\n",
        "        signal_echo = echo(audio_in, 0.1, fs)\n",
        "    '''\n",
        "  #  Set delay sample \n",
        "  delay_samples = int(delay * fs)\n",
        "  #Generate output signal for echo by adding the delay to the signal\n",
        "  output_signal = np.zeros(len(signal) + delay_samples)\n",
        "  output_signal[:len(signal)] = signal\n",
        "  output_signal[delay_samples:] += signal\n",
        "  return output_signal\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ew81_cDxNrN"
      },
      "outputs": [],
      "source": [
        "#Call echo function\n",
        "echo_sig = echo(s,0.01,fs)\n",
        "#Play audio\n",
        "ipd.Audio(echo_sig, rate=fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NwsLkYBM2s8"
      },
      "outputs": [],
      "source": [
        "#Call echo function\n",
        "echo_sig = echo(s,0.07,fs)\n",
        "#Play audio\n",
        "ipd.Audio(echo_sig, rate=fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkT8TriRM4Vd"
      },
      "outputs": [],
      "source": [
        "#Call echo function\n",
        "echo_sig = echo(s,0.5,fs)\n",
        "#Play audio\n",
        "ipd.Audio(echo_sig, rate=fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPxvKhDzxNrN"
      },
      "source": [
        "### 4.8 Comb Filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hcEcitMxNrO"
      },
      "source": [
        "You should observe that, with delays below $20$ msec in your function `echo()`, the signals combine to create a subtle ‘phasing’ effect. This is known as ‘comb filtering’ as the signal is effectively interfering with itself, and frequency components corresponding to multiples of the delay time are enhanced or cancelled out (due to ‘superposition’). Delays between $20$ and $100$ msecs give the effect of the voice being in a reverberant room. Delays above $100$ msecs sound like distant echoes.\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T10:**\n",
        "    \n",
        "* Visualise the impulse response of your function `echo()` as well as the transfer function. Can you give an explanation from havin a look at the transfer function, why this effect would be called *comb filter*?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX35xhBMxNrO"
      },
      "outputs": [],
      "source": [
        "#Call echo function\n",
        "echo_signal = echo(s,0.01,fs)\n",
        "w, h = sig.freqz(echo_signal, s, fs = fs, worN = 8000)\n",
        "#Plot graphs\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.title('Impulse Responce for echo()')\n",
        "plt.plot(w, np.abs(h))\n",
        "plt.xlim(0,1500)\n",
        "plt.grid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoJscwiexNrO"
      },
      "source": [
        "**Answer to question in Task T10:**\n",
        "\n",
        "<span style=\"font-weight:bold;color:orange\">\n",
        "    This effect is called a comb filter as the shape of the impulse responce looks like a comb when visualised.\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xnIwypKxNrO"
      },
      "source": [
        "### 4.9 Flanger \n",
        "\n",
        "It is possible to use an LFO to vary the delay. The resulting effect is known as a *flanger*.\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T11:**\n",
        "    \n",
        "* Add an LFO to your ‘delay’ to create a ‘flanger’, and experiment with different settings. Note that you will need to scale the output of the LFO, and you will get different effects depending on whether the delayed signal is mixed with the original or not.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "NsMpOuSexNrO"
      },
      "outputs": [],
      "source": [
        "def flanger(signal, delay, fs, speed_hz, depth , square_curve):\n",
        "  \"\"\"Apply a flanger effect to the signal.\n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : ndarray\n",
        "        The input signal.\n",
        "    delay : float\n",
        "        The delay in seconds.\n",
        "    fs : int\n",
        "        The sampling frequency.\n",
        "    speed_hz : float\n",
        "        The speed of the effect in Hz.\n",
        "    depth : float\n",
        "        The depth of the effect (between 0 and 1).\n",
        "    square_curve : bool\n",
        "        If True, the curve of the effect will be square.\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        The output signal.\n",
        "    \"\"\"\n",
        "    #Length of the signal\n",
        "  length = len(signal)\n",
        "  #Convert Input to array\n",
        "  signal = np.asarray(signal)\n",
        "  # Make itto samples\n",
        "  delay_sample = int(delay * fs)\n",
        "  depth_sample = int(depth * fs)\n",
        "  #Generate the signal\n",
        "  generated_signal = lfo(speed_hz, depth, length, fs, square_curve)\n",
        "  generated_signal = (generated_signal + 1) /2\n",
        "  generated_signal = generated_signal * depth_sample\n",
        "  generated_signal = generated_signal.astype(int)\n",
        "  #Apply the flanger effect looping over the signal and adding the delayed signal\n",
        "  output_signal=np.zeros_like(signal)\n",
        "  for i in range(length):\n",
        "    output_signal[i] = signal[i] + signal[i - delay_sample - generated_signal[i]]\n",
        "  return output_signal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlqtJJhpxNrO"
      },
      "outputs": [],
      "source": [
        "#Call flanger function\n",
        "signal_flanger = flanger(s,0.1,fs,50,0.1,False)\n",
        "#Play audio\n",
        "ipd.Audio(signal_flanger, rate = fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YQ88UEsxNrO"
      },
      "source": [
        "## 5 Frequency Analysis\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
        "    \n",
        "**Question Q5:**\n",
        "\n",
        "* COM3502-4502-6502: \n",
        "    * What does FFT stand for and what does an FFT do?\n",
        "* COM4502-6502 ONLY: What is a DFT and how is it different from an FFT?\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNgrsvh7xNrO"
      },
      "source": [
        "**Answer to Question Q5:**\n",
        "\n",
        "<span style=\"font-weight:bold;color:orange\">\n",
        "    FFT stands for \"Fast Fourier Transform\" and this is an algorithm to quickly calculate the discrete Fourier transform of a sequence\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhLO2Ef3xNrO"
      },
      "source": [
        "## Creating the Spectrogram Step-by-Step (for COM4502-6502 only)\n",
        "\n",
        "The magnitude $|X[n, \\ell]|$ of the STFT for all $n$ and $\\ell$ is known as the [spectrogram](https://en.wikipedia.org/wiki/Spectrogram) of a signal. It is frequently used to analyze signals in the time-frequency domain, for instance by a [spectrum analyzer](https://en.wikipedia.org/wiki/Spectrum_analyzer). It can be interpreted as a *image* of the signal with (block) time direction on the $x$ axis and (discrete) frequency $n$ on the y axis.\n",
        "\n",
        "From Lab Sheet 3 we already know how to brack a long signal into block, a.k.a. frames.\n",
        "\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task 12: Manual Spectrogram Calculation (for COM4502-6502 only)**\n",
        "    \n",
        "<ul>\n",
        "    <li> \n",
        "        Implement a function <code>calc_SpectralPoint(xk,n)</code> which calculates a spectral point for one discrete frequency $n$ from a input frame $x[k]$, i.e. a function which implements the well-known DFT equation\n",
        "    $$\n",
        "    \\mathrm{DFT}\\{x[k]\\}   =  X[n] = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}\n",
        "    $$ \n",
        "    for one fixed $n$.\n",
        "    </li>\n",
        "    <li> \n",
        "        Implement a very similar function <code>calc_SpectralPointWindowed(xk,n)</code> which calculates a spectral point for one discrete frequency $n$ from a input frame $x[k]$, but in addition applies a window function $w[k]$ to the frame $x[k]$, i.e. the function should calculate\n",
        "    $$\n",
        "    \\mathrm{DFT}\\{w[k] \\cdot x[k]\\}   =  X^{\\mathrm{w}}[n] = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} w[k] x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}\n",
        "    $$ \n",
        "    for one fixed $n$. The window should have the same length $L_{\\mathrm{DFT}}$ as your frame and should be one of the windows we discussed during the lecture.\n",
        "    </li>\n",
        "    <li> \n",
        "        The functions above only calculates one spectral value at a time. To obtain a full spectrum , implement a function <code>calc_Manitude_Spectrum()</code> which transforms every windowed frame to the frequency domain and calculates all positive frequencies, i.e. for $0 \\leq n \\leq L_{\\mathrm{DFT}}/2+1$.\n",
        "    </li>\n",
        "    <li> \n",
        "        Create a function <code>create_spectrogram()</code>, which splits the complete input sequence (e.g. a loaded WAVE file) into blocks of length $L_{\\mathrm{DFT}}$. These may be overlapping. For each block the spectrum should be calculated using the previously implemented function <code>calc_Manitude_Spectrum()</code> and all spectra should be collected to form a spectrogram (e.g. as columns of a matrix).\n",
        "    </li>\n",
        "    <li> \n",
        "        Concatenate the resulting spectra to a spectrogram and display the resulting spectrogram. You can use <code>matplotlib</code>'s <code><a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\">imshow()</a></code> function for manually plotting the spectrogram image. Note that a spectrogram is usally shown in dB scaling.\n",
        "    </li>\n",
        "    <li>\n",
        "        Visulalise the input signal $x[k]$ as spectrogram for (i) a speech signal and (ii) for a chirp/sweep signal. \n",
        "    </li>\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlNyqXMlxNrP"
      },
      "source": [
        "Implement the  DFT equation\n",
        "    $$\\mathrm{DFT}\\{x[k]\\}   =  X[n] = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}$$ for one fixed $n$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "fUwppFscxNrP"
      },
      "outputs": [],
      "source": [
        "def calc_SpectralPoint(xk,n):\n",
        "    '''\n",
        "    Implementation of the Discrete Fourier Transform (DFT).\n",
        "    Calculates the Fourier coefficient X[n] for one discrete frequency n \n",
        "    \n",
        "    Input: \n",
        "    xk:     time domain signal vector\n",
        "    n:      discrecte frequency to be calculated\n",
        "    \n",
        "    Output \n",
        "    Xn : dicrete frequency domain point for frequency n\n",
        "    '''\n",
        "    \n",
        "    # Your code here\n",
        "    # ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yCzSch1xNrP"
      },
      "source": [
        "Implement DFT of windowed frame\n",
        "$$\\mathrm{DFT}\\{w[k] \\cdot x[k]\\}   =  X^{\\mathrm{w}}[n]  = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} w[k] x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}$$ for one fixed $n$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "wyaLF289xNrP"
      },
      "outputs": [],
      "source": [
        "def calc_SpectralPointWindowed(xk,n,window=False):\n",
        "    '''\n",
        "    Implementation of the Discrete Fourier Transform (DFT).\n",
        "    Calculates the Fourier coefficient X[n] for one discrete frequency n \n",
        "    \n",
        "    Input: \n",
        "    xk:     time domain signal vector\n",
        "    n:      discrecte frequency to be calculated\n",
        "    window: (optional): can be False (no window) or a window name from   \n",
        "            the list of available numpy window functions, e.g. \n",
        "            np.hamming, np.bartlett, np.blackman, np.hanning, np.kaiser\n",
        "            type: function\n",
        "            (feel free to implement the window differently)\n",
        "    \n",
        "    Output \n",
        "    Xn : dicrete frequency domain point for frequency n\n",
        "    '''\n",
        "    # Your code here\n",
        "    # L_DFT = ???\n",
        "    # ...\n",
        "    \n",
        "    if window == False:\n",
        "        win = np.ones(L_DFT) # this is a window with no effect\n",
        "    else:\n",
        "        None # replace this by your own window\n",
        "        \n",
        "    # Your code here\n",
        "    # ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhfbUZ5rxNrP"
      },
      "source": [
        "The following function <code>calc_Manitude_Spectrum()</code> is supposed to transform every (windowed or not windowed) frame to the frequency domain and to calculate all positive frequencies, i.e. $X[n]$ or $X^{\\mathrm{w}}[n]$ for $0 \\leq n \\leq L_{\\mathrm{DFT}}/2+1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "33MsAaucxNrP"
      },
      "outputs": [],
      "source": [
        "def calc_Manitude_Spectrum(xk):\n",
        "    '''\n",
        "    Compute Fourier coefficients up to the Nyquest Limit (fs/2), i.e. Xn for n=0,...,L_DFT/2 \n",
        "    using one of the two functions created before.\n",
        "    and multiply the absolute value of the Fourier coefficients by 2, \n",
        "    to account for the symetry of the Fourier coefficients above the Nyquest Limit. \n",
        "    '''\n",
        "    # Your code here\n",
        "    # ...\n",
        "    \n",
        "    # probably there should be a loop over n here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTVSSKdZxNrQ"
      },
      "source": [
        "The following function <code>create_spectrogram()</code> should calculate all spectra needed for your spectrogram. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "-_QoZk6SxNrQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "17900507-1ef7-4b83-889e-df76aea2db78"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-326-03eac05bf9a4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def create_spectrogram(x, L_DFT=512, noverlap):\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
          ]
        }
      ],
      "source": [
        "def create_spectrogram(x, L_DFT=512, noverlap):\n",
        "    '''\n",
        "           x: original time series\n",
        "       L_DFT: The number of data points used in each block for the DFT. The default value is 512. \n",
        "    noverlap: The number of points of overlap between blocks. The default value is 256. \n",
        "    '''\n",
        "    # Your code here\n",
        "    # ...\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c0tx2J1xNrQ"
      },
      "source": [
        "The following function can be used to actually display the created spectrogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ3qwhIWxNrQ"
      },
      "outputs": [],
      "source": [
        "def plot_spectrogram( #..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tQoNe60xNrQ"
      },
      "source": [
        "The following code actually calculates and plots your spectrogram (for the two signals mentioned above). Feel free to adapt parameters `L_DFT` and `noverlap`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV1542XTxNrQ"
      },
      "outputs": [],
      "source": [
        "# load or create signal\n",
        "\n",
        "# create and plot spectrogram (generated using your functions above)\n",
        "L_DFT    = 256 # DFT length\n",
        "noverlap = 84  # number of overlapping samples\n",
        "starts, spec = create_spectrogram( #...\n",
        "plot_spectrogram(#..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxqFGCyexNrQ"
      },
      "source": [
        "## 6 Equaliser (for COM4502-6502 only)\n",
        "\n",
        "We want to design an equaliser like shown in the picture below as a hardware system.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Yamaha_EQ-500_Graphic_Equalizer.jpg/1920px-Yamaha_EQ-500_Graphic_Equalizer.jpg\" align=\"center\" style=\"width: 500px;\"/>\n",
        "<center><span style=\"font-size:smaller\">\n",
        "    Picture taken from <a href=\"https://simple.wikipedia.org/wiki/Equalization_(audio)\">Wikipedia</a>, license: <a href=\"https://creativecommons.org/licenses/by/2.0/\">CC BY 2.0</a>\n",
        "</span></center>\n",
        "\n",
        "\n",
        "The following function realises one of the sliders in software."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQyRILzOxNrQ"
      },
      "outputs": [],
      "source": [
        "def peaking_filter(gain,center_freq,q,fs):\n",
        "    \"\"\"\n",
        "    Derive coefficients for a peaking filter with a given amplitude and\n",
        "     bandwidth.  All coefficients are calculated as described in Zolzer's\n",
        "     DAFX book (p. 50 - 55).  This algorithm assumes a constant q-term\n",
        "     is used through the equation.\n",
        "    \n",
        "    Usage:     `b,a` = peaking_filter(gain,center_freq, q,fs)\n",
        "                `gain` is the logrithmic gain (in dB)\n",
        "                `center_freq` is the center frequency\n",
        "                `q` is q-term equating to (Fb / Fc)\n",
        "                `fs` is the sampling rate\n",
        "    \n",
        "    Author:    Jeff Tackett 08/22/05\n",
        "    Port to Python by George Close 10/07/21\n",
        "    \"\"\"\n",
        "    \n",
        "    gain = np.float32(gain)\n",
        "    k = np.tan((np.pi*center_freq)/fs)\n",
        "    V0 = 10**((gain)/20)\n",
        "    # invert gain if a cut\n",
        "    if V0 < 1:\n",
        "        V0 = 1/V0\n",
        "\n",
        "    # Boost\n",
        "    if gain > 0:\n",
        "        b0 = (1 + ((V0/q)*k)+ k**2) / (1+((1/q)*k)+k**2)\n",
        "        b1 = (2 * (k**2 - 1)) / (1 + ((1/q)*k) + k**2);\n",
        "        b2 = (1 - ((V0/q)*k) + k**2) / (1 + ((1/q)*k) + k**2);\n",
        "        a1 = b1;\n",
        "        a2 =  (1 - ((1/q)*k) + k**2) / (1 + ((1/q)*k) + k**2);\n",
        "    # Cut\n",
        "    elif gain <0:\n",
        "        b0 = (1 + ((1/q)*k) + k**2) / (1 + ((V0/q)*k) + k**2);\n",
        "        b1 =       (2 * (k**2 - 1)) / (1 + ((V0/q)*k) + k**2);\n",
        "        b2 = (1 - ((1/q)*k) + k**2) / (1 + ((V0/q)*k) + k**2);\n",
        "        a1 = b1;\n",
        "        a2 = (1 - ((V0/q)*k) + k**2) / (1 + ((V0/q)*k) + k**2);\n",
        "    #gain is 0\n",
        "    else:\n",
        "        b0 = V0;\n",
        "        b1 = 0;\n",
        "        b2 = 0;\n",
        "        a1 = 0;\n",
        "        a2 = 0;\n",
        "    a = [  1, a1, a2];\n",
        "    b = [ b0, b1, b2];\n",
        "    return b,a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0JQaSwexNrR"
      },
      "source": [
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T13: (for COM4502-6502 only)**\n",
        "    \n",
        "* Visualise the frequency response of one filter.\n",
        "* Implement a cascade of filters to realise an equaliser.\n",
        "* Visualise the frequency response of your equaliser filter and the input and (filtered) output signal.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e57SL6q-xNrR"
      },
      "outputs": [],
      "source": [
        "# Your code here \n",
        "#\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKUdw-FQxNrR"
      },
      "source": [
        "## 6. Prepare for submission\n",
        "\n",
        "<br>\n",
        "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
        "    \n",
        "**Task T14:**\n",
        " \n",
        "* Clear all cell outputs to reduce the file size (in Jupyter Notebooks clivk on \"Cell->All Output->Clear\")\n",
        "* Create a `.zip` file named `YourName.zip` containing this Jupyter Notebook files as well as all other file necessary to run this notebook (**if such exist**, e.g. if you created (additional) WAVE files). \n",
        "* Hand-in your `.zip` file via Blackboard.\n",
        "    \n",
        "\n",
        "<span style=\"font-weight:bold;color:red;text-align:center;\">**Important: For marking, we expect your code to work ‘out of the box’.**</span> This means that no additional software should have to be installed to make the Notebook run. If you only used libraries known from the Speech Processing Lab classes, you should be safe here.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALab9HfkxNrR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}